# SberClassification
**–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Ç–æ–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –§–õ - –°–±–µ—Ä üíº**

**–ú–µ—Ç—Ä–∏–∫–∏ AUC üìä:**
- 0.7613 - CatBoost —Å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º –∏ –≤—ã–∫—Ä—É—Ç–∞—Å–∞–º–∏
- 0.7601 - CatBoost —Å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º
- 0.7561 - XGBoost
- 0.6906 - Classifier_base —Å 4 –ª–∏–Ω–µ–π–Ω—ã–º–∏ —Å–ª–æ—è–º–∏
- 0.7010 - Classifier_dropout
- 0.7072 - Classifier_dropout2
- 0.7308 - Classifier_dropout2 —Å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º
- 0.7463 - Classifier_dropout2 —Å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º –∏ CatBoost

**–ú–æ–¥–µ–ª–∏ –∏ –ø–æ–¥—Ö–æ–¥—ã üõ†Ô∏è:**
- **CatBoostClassifier:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º –∏ –≤—ã–∫—Ä—É—Ç–∞—Å–∞–º–∏, –∞ —Ç–∞–∫–∂–µ –±–µ–∑ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: iterations=7500, learning_rate=0.01, depth=6, loss_function='MultiClass', eval_metric='AUC', random_seed=0, class_weights=[1, 12], task_type='GPU').
```python
from catboost import CatBoostClassifier

model_catboost = CatBoostClassifier(iterations=7500,
                                    learning_rate=0.01,
                                    depth=6,
                                    loss_function='MultiClass',
                                    eval_metric='AUC',
                                    random_seed=0,
                                    class_weights=[1, 12],  # –ø—Ä–∏–º–µ—Ä–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
                                    task_type='GPU')
```
- **XGBoost:** –ü—Ä–∏–º–µ–Ω—è–ª—Å—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å AUC –º–µ—Ç—Ä–∏–∫–æ–π 0.7561.
```python
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ XGBoost
model_xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05, max_depth=4, random_state=0)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤—ã–≤–æ–¥–æ–º –ª–æ–≥–æ–≤ –∏ –≥—Ä–∞—Ñ–∏–∫–∞
eval_set = [(X_train, y_train), (X_val, y_val)]  # –£–∫–∞–∑—ã–≤–∞–µ–º –æ–±—É—á–∞—é—â–∏–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
model_xgb.fit(X_train, y_train, eval_set=eval_set, eval_metric="auc", verbose=True)
```
- **Classifier_base, Classifier_dropout, Classifier_dropout2:** –õ–∏–Ω–µ–π–Ω—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏ –∏ —Å–ª–æ—è–º–∏.
```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt

# Define your neural network model
class Classifier(nn.Module):
    def __init__(self, input_size):
        super(Classifier, self).__init__()
        self.fc0 = nn.Linear(input_size, 1028)
        self.fc1 = nn.Linear(1028, 256)
        self.fc2 = nn.Linear(256, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)  # Adding dropout for regularization

    def forward(self, x):
        x = torch.relu(self.fc0(x))
        x = self.dropout(x)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = torch.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.sigmoid(self.fc3(x))
        return x
    
    def get_embed(self, x):
        x = torch.relu(self.fc0(x))
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return x
```
- **–§–∏—á–µ –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥:** –ü—Ä–∏–º–µ–Ω–µ–Ω –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π.
```python
categorical_features = [col for col in df.columns[1:] if df[col].nunique() < 20]
numerical_features = [col for col in df.columns[1:] if df[col].nunique() >= 20]
# –ú–µ—Ç–æ–¥ Label Encoding
for feature in categorical_features:
    df[feature + '_label_encoded'] = df[feature].astype('category').cat.codes

# –ú–µ—Ç–æ–¥ One-Hot Encoding
encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
encoded_features = pd.DataFrame(encoder.fit_transform(df[categorical_features]))
encoded_features.columns = encoder.get_feature_names_out(categorical_features)

df = pd.concat([df, encoded_features], axis=1)
```
- **–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å —É—á–µ—Ç–æ–º —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö, –≤—ã–±—Ä–æ—Å–æ–≤ –∏ —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
```python
# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
scalers = {
    #"StandardScaler": StandardScaler(),
    #"MinMaxScaler": MinMaxScaler(),
    "RobustScaler": RobustScaler(),
    #"Normalizer": Normalizer(),
    #"MaxAbsScaler": MaxAbsScaler(),
}

scaled_dfs = []

for scaler_name, scaler in tqdm(scalers.items()):
    scaled_data = scaler.fit_transform(df[numerical_features])
    scaled_df = pd.DataFrame(scaled_data, columns=[f"{feature}_{scaler_name}" for feature in numerical_features])
    scaled_dfs.append((scaler_name, scaled_df))
    
# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
df = pd.concat([df] + [scaled_df for _, scaled_df in scaled_dfs], axis=1)
```
- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞–ª–∏ –±–æ–ª–µ–µ 1000 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —Ñ–∏—á–µ –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –ø–æ–ª—É—á–µ–Ω–æ –±–æ–ª–µ–µ 4000 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
- **Voting –∞–Ω—Å–∞–º–±–ª—å:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
```python
  from sklearn.ensemble import VotingClassifier
voting_classifier = VotingClassifier(estimators=[('catboost', model_catboost), ('xgboost', model_xgboost)], voting='soft')
voting_classifier.fit(X_train, y_train)
```
- **CatBoost –∏ XGBoost:** –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞, –ø—Ä–∏–º–µ–Ω—è–µ–º—ã–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.

**–ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è üõ†Ô∏è:**
- **–†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö:** –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –∏ –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
- **–í—ã–±—Ä–æ—Å—ã:** –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –º–µ—Ä—ã –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö.
- **–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞–∏–≤–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:** –ú–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.


**–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ üîç:**
- –ö–æ–¥ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±—É–¥–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
- **permutation importance:** –í—ã—á–∏—Å–ª–µ–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –º–æ–¥–µ–ª—è—Ö –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.
```python
from sklearn.inspection import permutation_importance
scoring = 'roc_auc'
r = permutation_importance(model, X_test, y_test,
                           n_repeats=20,
                           random_state=0,scoring = scoring)
for i in r.importances_mean.argsort()[::-1]:
    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:
        print(f"{X_test.columns[i]:<8}"
              f"{r.importances_mean[i]:.3f}"
              f" +/- {r.importances_std[i]:.3f}")
```
- **RecursiveByShapValues**:
```python

clf.select_features(
                train_pool,
                eval_set=test_pool,
                features_for_select = list(X_train.columns),
                num_features_to_select=500,
                steps=10,
                algorithm='RecursiveByShapValues',
                shap_calc_type='Regular',
                train_final_model=True,
                plot=False,
                verbose = 1000)
```
- **shapley_feature_ranking**:
```python

def shapley_feature_ranking(explanation,func = np.mean):
    '''
    func –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é np.mean, –Ω–æ –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞–ø—Ä–∏–º–µ—Ä –Ω–∞ np.max
    '''
    feature_order = np.argsort(func(np.abs(explanation.values), axis=0))
    
    return pd.DataFrame(
        {
            "features": [explanation.feature_names[i] for i in feature_order][::-1],
            "importance": [
                func(np.abs(explanation.values), axis=0)[i] for i in feature_order
            ][::-1],
        }
    )


feature_names = X_train.columns

shap_values = explainer.shap_values(Pool(X_test, y_test, cat_features=cat_feature_names))

base_values = np.mean(shap_values)

explanation = shap.Explanation(values=shap_values, data=X_test, feature_names=feature_names, base_values=base_values)

important_feature = shapley_feature_ranking(explanation)
plt.show(important_feature.head(10))
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ üí°:**
- –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω —Ä—è–¥ –º–æ–¥–µ–ª–µ–π –∏ –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—é –æ—Ç—Ç–æ–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –§–õ –≤ –°–±–µ—Ä–µ.
- –ú–æ–¥–µ–ª–∏ CatBoost –ø–æ–∫–∞–∑–∞–ª–∏ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ç—Ä–∏–∫–µ AUC.
- –ü—Ä–∏–º–µ–Ω–µ–Ω—ã —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö, —Ñ–∏—á–µ –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤.
- –†–µ—à–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å—é –¥–∞–Ω–Ω—ã—Ö, –≤—ã–±—Ä–æ—Å–∞–º–∏ –∏ –Ω–∏–∑–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
- –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é, –≤–∫–ª—é—á–∞—è –∫–æ–¥ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤.

–†–µ—à–µ–Ω–∏–µ: sber.ipynb
